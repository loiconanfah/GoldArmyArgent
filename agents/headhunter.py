"""
Agent Headhunter ‚Äî Extraction Deep OSINT de Profils LinkedIn.
Architecture 3 √©tapes:
  1. Gemini 2.0 Flash + Google Search Grounding ‚Üí Identifier les noms des d√©cideurs
  2. Gemini generate_with_sources (m√©tadonn√©es) ‚Üí Extraire les vraies URLs /in/ des sources grounding
  3. Gemini ‚Üí Enrichir chaque profil (r√¥le, snippet) √† partir des URLs r√©elles
"""
from typing import Dict, Any, List, Optional
from loguru import logger
import urllib.parse
import json
import re
import asyncio

from core.agent_base import BaseAgent
from config.settings import settings


class HeadhunterAgent(BaseAgent):
    """Agent IA pour identifier et extraire des profils de d√©cideurs."""

    def __init__(self, **kwargs):
        kwargs.setdefault("agent_type", "headhunter")
        kwargs.setdefault("name", "HeadhunterAgent")
        kwargs.setdefault("temperature", 0.1)
        super().__init__(**kwargs)

    async def think(self, user_input: Dict[str, Any]) -> Dict[str, Any]:
        return {"status": "success"}

    async def act(self, command: Dict[str, Any]) -> str:
        return "Action completed"

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    async def find_decision_makers(self, params: Dict[str, Any]) -> List[Dict[str, str]]:
        """
        Strat√©gie en 3 √©tapes pour obtenir de vraies URLs LinkedIn /in/ :
        1. Identifier les noms via Gemini Grounding
        2. Extraire les URLs source directes des m√©tadonn√©es de Grounding 
        3. Enrichir les profils avec ces URLs r√©elles
        """
        company_name = params.get("company_name", "").strip()
        if not company_name:
            return []

        logger.info(f"üïµÔ∏è OSINT Headhunter pour: {company_name}")

        # ‚îÄ‚îÄ √âTAPE 1 + 2 : Grounding avec extraction des URLs sources ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        # On utilise plusieurs requ√™tes cibl√©es pour maximiser les profils trouv√©s
        search_queries = [
            f'site:linkedin.com/in/ "{company_name}" recruiter OR "talent acquisition" OR "responsable RH" OR "HR manager"',
            f'site:linkedin.com/in/ "{company_name}" "directeur ressources humaines" OR "VP RH" OR "Chief Human Resources"',
        ]

        linkedin_profiles: List[Dict] = []  # {url, title, snippet}
        seen_urls: set = set()

        for search_q in search_queries:
            if len(linkedin_profiles) >= 6:
                break

            prompt = f"""
                Effectue une recherche Google pour exactement cette requ√™te et retourne les r√©sultats:
                {search_q}
                
                Retourne UNIQUEMENT un JSON tableau, chaque √©l√©ment contient l'URL EXACTE du r√©sultat Google, le titre et le snippet.
                Format: [{{"url":"URL EXACTE", "title":"Titre", "snippet":"Extrait"}}]
                N'invente pas d'URLs. Utilise UNIQUEMENT les URLs r√©elles des r√©sultats de recherche Google.
            """

            try:
                # On bypasse UnifiedClient pour acc√©der directement √† GeminiClient avec generate_with_sources
                from llm.gemini_client import GeminiClient
                gemini = GeminiClient()
                text_resp, source_urls = await gemini.generate_with_sources(
                    prompt,
                    model="gemini-2.0-flash",
                    temperature=0.0,
                    tools=[{"googleSearch": {}}]
                )
                logger.debug(f"Sources Grounding ({len(source_urls)} URLs): {source_urls[:5]}")

                # Filtrer uniquement les URLs LinkedIn /in/
                for url in source_urls:
                    match = re.search(r'https?://(?:\w+\.)?linkedin\.com/in/([\w\-]+)', url)
                    if match:
                        clean_url = f"https://www.linkedin.com/in/{match.group(1)}"
                        if clean_url not in seen_urls:
                            seen_urls.add(clean_url)
                            linkedin_profiles.append({
                                "linkedin_url": clean_url,
                                "title_raw": "",
                                "snippet_raw": ""
                            })

                # Si les URLs sources n'ont pas fourni de /in/ links, essayer le texte JSON retourn√©
                if not linkedin_profiles:
                    clean = text_resp.strip()
                    if "```json" in clean:
                        clean = clean.split("```json")[1].split("```")[0].strip()
                    elif "```" in clean:
                        clean = clean.split("```")[1].split("```")[0].strip()
                    try:
                        raw_list = json.loads(clean)
                        for item in raw_list:
                            url = item.get("url", "")
                            match = re.search(r'https?://(?:\w+\.)?linkedin\.com/in/([\w\-]+)', url)
                            if match:
                                clean_url = f"https://www.linkedin.com/in/{match.group(1)}"
                                if clean_url not in seen_urls:
                                    seen_urls.add(clean_url)
                                    linkedin_profiles.append({
                                        "linkedin_url": clean_url,
                                        "title_raw": item.get("title", ""),
                                        "snippet_raw": item.get("snippet", "")
                                    })
                    except Exception:
                        pass

            except Exception as e:
                logger.warning(f"Grounding avec sources: {e}")

        logger.info(f"üîó {len(linkedin_profiles)} profils /in/ extraits des sources Google pour {company_name}")

        # ‚îÄ‚îÄ √âTAPE 3 : Enrichissement des profils trouv√©s ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        if linkedin_profiles:
            urls_text = "\n".join(f"- {p['linkedin_url']}" for p in linkedin_profiles[:5])
            enrich_prompt = f"""
            Tu es un expert OSINT RH.
            Voici une liste d'URLs de profils LinkedIn de personnes chez '{company_name}':
            {urls_text}
            
            Pour chaque URL, d√©duis le nom probable (depuis le slug URL), le r√¥le, et g√©n√®re un snippet strat√©gique (15 mots max).
            Conserve les URLs EXACTEMENT comme fournies.
            
            R√©ponds UNIQUEMENT avec un tableau JSON (sans markdown):
            [{{"name":"Pr√©nom Nom", "role":"Titre", "linkedin_url":"URL EXACTE", "snippet":"R√©sum√©..."}}]
            """
            try:
                resp = await self.generate_response(enrich_prompt, model="gemini-2.0-flash", temperature=0.1)
                clean = resp.strip()
                if "```json" in clean:
                    clean = clean.split("```json")[1].split("```")[0].strip()
                elif "```" in clean:
                    clean = clean.split("```")[1].split("```")[0].strip()
                enriched = json.loads(clean)
                
                # Garantie finale: url doit contenir /in/
                final = []
                for e in enriched:
                    url = e.get("linkedin_url", "")
                    if "/in/" in url:
                        final.append(e)
                    else:
                        # chercher l'url original dans linkedin_profiles
                        if linkedin_profiles:
                            e["linkedin_url"] = linkedin_profiles[len(final)]["linkedin_url"]
                            final.append(e)

                logger.success(f"‚úÖ {len(final)} profils enrichis avec URLs directes pour {company_name}")
                return final
            except Exception as ex:
                logger.warning(f"Enrichissement Gemini √©chou√© ({ex}). Fallback profils bruts.")
                # Renvoie les URLs brutes avec nom d√©duit du slug
                return [{
                    "name": p["linkedin_url"].split("/in/")[-1].replace("-", " ").title(),
                    "role": "D√©cideur / Recruteur",
                    "linkedin_url": p["linkedin_url"],
                    "snippet": f"Profil LinkedIn identifi√© chez {company_name}"
                } for p in linkedin_profiles[:5]]

        # ‚îÄ‚îÄ FALLBACK TOTAL : Gemini Grounding direct avec consigne ultra-stricte ‚îÄ
        logger.warning(f"‚ö†Ô∏è Aucune URL /in/ extraite. Tentative Grounding final pour {company_name}...")
        fallback_prompt = f"""
        Recherche Google: site:linkedin.com/in/ "{company_name}" recruiter OR "talent acquisition"
        
        LISTE les r√©sultats EXACTS trouv√©s sur Google (pas invent√©s).
        Retourne UNIQUEMENT un tableau JSON:
        [{{"name":"...", "role":"...", "linkedin_url":"https://www.linkedin.com/in/...", "snippet":"..."}}]
        
        R√àGLE ABSOLUE: linkedin_url doit contenir /in/. JAMAIS de lien g√©n√©rique.
        """
        try:
            resp = await self.generate_response(
                fallback_prompt,
                model="gemini-2.0-flash",
                temperature=0.0,
                tools=[{"googleSearch": {}}]
            )
            clean = resp.strip()
            if "```json" in clean: clean = clean.split("```json")[1].split("```")[0].strip()
            elif "```" in clean: clean = clean.split("```")[1].split("```")[0].strip()
            profiles = json.loads(clean)
            
            validated = []
            for p in profiles:
                url = p.get("linkedin_url", "")
                if "/in/" in url:
                    validated.append(p)
            
            logger.success(f"‚úÖ Fallback Grounding: {len(validated)} profils pour {company_name}")
            return validated
        except Exception as e:
            logger.error(f"‚ùå Headhunter totalement √©chou√©: {e}")
            return []


# Instance globale
headhunter_agent = HeadhunterAgent()
